# === Cell 1: Install necessary packages ===
!pip install pandas openpyxl requests python-Levenshtein

# === Cell 2: Imports and logging ===
import pandas as pd
import requests
import time
import logging
from difflib import SequenceMatcher
from Levenshtein import ratio as levenshtein_ratio

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# === Cell 3: Configure API access ===
API_KEY = 'your-api-key-here'
INSTITUTION_TOKEN = 'your-institutional-token-here'

headers = {
    'X-ELS-APIKey': API_KEY,
    'X-ELS-Insttoken': INSTITUTION_TOKEN,
    'Accept': 'application/json'
}

AUTHOR_SEARCH_URL = "https://api.elsevier.com/content/search/author"
SCOPUS_SEARCH_URL = "https://api.elsevier.com/content/search/scopus"

# === Cell 4: Test SCOPUS API Key and Token ===
test_params = {
    'query': 'AUTHLASTNAME(Einstein) AND AUTHFIRST(Albert)',
    'count': 1
}

test_resp = requests.get(AUTHOR_SEARCH_URL, headers=headers, params=test_params)
print("Test Status Code:", test_resp.status_code)

# Show a short snippet of the response content (optional)
try:
    print("Test Response Snippet:", test_resp.json())
except Exception as e:
    print("Could not parse JSON. Raw text:", test_resp.text[:300])

# === Cell 5: Load Excel File ===
input_path = 'D:/aa030/input/aa-counterintel-input.xlsx'
df = pd.read_excel(input_path, engine='openpyxl')
print(f"Loaded {len(df)} authors from input file.")

# === Cell 6a: Define helper for fuzzy affiliation match ===
def fuzzy_match(a, b):
    a, b = a.lower(), b.lower()
    return levenshtein_ratio(a, b) > 0.80 or a in b or b in a

# === Cell 6bc-DOItoEIDInspect: Get authors and affiliations from a DOI ===

def inspect_authors_from_doi(doi):
    # Step 1: Find the EID from the DOI
    search_url = "https://api.elsevier.com/content/search/scopus"
    params = {
        'query': f'DOI({doi})',
        'count': 1
    }
    resp = requests.get(search_url, headers=headers, params=params)
    if resp.status_code != 200:
        print(f"Failed to retrieve EID from DOI. Status code: {resp.status_code}")
        return

    results = resp.json().get('search-results', {}).get('entry', [])
    if not results:
        print("No article found for this DOI.")
        return

    eid = results[0].get('eid')
    print(f"Found EID: {eid}\n")

    # Step 2: Retrieve abstract and list authors + affiliations
    abstract_url = f"https://api.elsevier.com/content/abstract/eid/{eid}"
    abstract_resp = requests.get(abstract_url, headers=headers)
    if abstract_resp.status_code != 200:
        print(f"Failed to retrieve abstract metadata. Status code: {abstract_resp.status_code}")
        return

    try:
        author_list = abstract_resp.json()['abstracts-retrieval-response']['authors']['author']
    except Exception:
        print("No author metadata found in abstract.")
        return

    print("=== AUTHORS AND AFFILIATIONS ===")
    for author in author_list:
        name = f"{author.get('ce:given-name', '')} {author.get('ce:surname', '')}".strip()
        scopus_id = author.get('@auid', 'N/A')
        affil = author.get('affiliation', {})
        affil_name = affil.get('affilname', 'N/A') if isinstance(affil, dict) else 'N/A'
        affil_city = affil.get('affiliation-city', '') if isinstance(affil, dict) else ''
        affil_country = affil.get('affiliation-country', '') if isinstance(affil, dict) else ''
        location = ", ".join([x for x in [affil_name, affil_city, affil_country] if x])
        print(f"- {name} (SCOPUS ID: {scopus_id})\n  Affiliation: {location if location else 'N/A'}\n")

# === EXAMPLE USAGE ===
inspect_authors_from_doi("10.1016/j.jclepro.2023.139200")


# === Cell 6bz-DOCQUERY: Pull documents and paper-level affiliations for a SCOPUS ID ===

def inspect_documents_by_author_id(scopus_id, max_docs=20):
    base_url = "https://api.elsevier.com/content/search/scopus"
    params = {
        'query': f"AU-ID({scopus_id})",
        'view': 'COMPLETE',
        'count': 25,
        'start': 0
    }

    docs = []
    while len(docs) < max_docs:
        resp = requests.get(base_url, headers=headers, params=params)
        if resp.status_code != 200:
            print(f"Error: {resp.status_code}")
            return

        page = resp.json().get('search-results', {})
        entries = page.get('entry', [])
        if not entries:
            break

        docs.extend(entries)
        params['start'] += 25
        if len(docs) >= int(page.get('opensearch:totalResults', 0)):
            break
        time.sleep(1)

    print(f"\nRetrieved {len(docs)} documents for SCOPUS ID {scopus_id}\n")
    for i, doc in enumerate(docs):
        print(f"[{i+1}] {doc.get('dc:title', 'Untitled')} ({doc.get('prism:coverDate', 'No Date')})")
        if 'author' in doc:
            for a in doc['author']:
                name = a.get('authname', 'Unknown')
                affils = a.get('affiliation', [])
                if isinstance(affils, dict):
                    affils = [affils]
                affil_strs = []
                for aff in affils:
                    parts = [
                        aff.get('affilname'),
                        aff.get('affiliation-city'),
                        aff.get('affiliation-country')
                    ]
                    affil_strs.append(", ".join([p for p in parts if p]))
                joined = " / ".join(affil_strs) if affil_strs else "No Affiliation Info"
                print(f"   - {name}: {joined}")
        print("---")

# === EXAMPLE USAGE ===
inspect_documents_by_author_id("57225158196")


# === Cell 6by-IDTEST: Inspect SCOPUS author metadata by SCOPUS ID ===

def inspect_scopus_author_by_id(scopus_id):
    url = f"https://api.elsevier.com/content/author/author_id/{scopus_id}?view=ENHANCED"
    resp = requests.get(url, headers=headers)
    print(f"Status code: {resp.status_code}\n")

    if resp.status_code != 200:
        print("Error retrieving author.")
        return

    try:
        data = resp.json()['author-retrieval-response'][0]
    except Exception as e:
        print("Error parsing JSON response.")
        return

    print("=== BASIC INFO ===")
    name = data.get('preferred-name', {})
    print(f"Full Name: {name.get('given-name', '')} {name.get('surname', '')}")
    print(f"SCOPUS ID: {scopus_id}")
    print(f"ORCID: {data.get('orcid', 'N/A')}")
    print(f"Document Count: {data.get('coredata', {}).get('document-count', 'N/A')}")
    print(f"Affiliation Current: {data.get('affiliation-current', {}).get('affiliation-name', 'N/A')}")

    print("\n=== SUBJECT AREAS ===")
    areas = data.get('subject-area', [])
    if isinstance(areas, dict): areas = [areas]
    for a in areas:
        print(f"- {a.get('area', '')} ({a.get('abbrev', '')})")

    print("\n=== AFFILIATION HISTORY ===")
    history = data.get('author-profile', {}).get('affiliation-history', {}).get('affiliation', [])
    if isinstance(history, dict): history = [history]
    for aff in history:
        parts = [
            aff.get('affil-name', ''),
            aff.get('affiliation-city', ''),
            aff.get('affiliation-country', ''),
            aff.get('start-date', '')
        ]
        print("- " + ", ".join([p for p in parts if p]))

# === EXAMPLE USAGE ===
inspect_scopus_author_by_id("57225158196")


# === Cell 6bx-TEST: Debug test for a single author match ===

max_candidates = 50
api_calls = {'author_search': 0, 'author_retrieval': 0}

def name_similarity(input_first, input_last, candidate_fullname):
    parts = candidate_fullname.lower().split()
    if len(parts) < 2:
        return False
    candidate_first = parts[0]
    candidate_last = parts[-1]
    return (
        candidate_last == input_last.lower() and
        levenshtein_ratio(input_first.lower(), candidate_first) > 0.8
    )

def fuzzy_match(a, b):
    a, b = a.lower(), b.lower()
    return levenshtein_ratio(a, b) > 0.80 or a in b or b in a

def run_test_case(first, last, affil_year_pairs):
    name_queries = [
        f"AUTHLASTNAME({last}) AND AUTHFIRST({first})",
        f"AUTHLASTNAME({last}) AND AUTHFIRST({first[0]})"
    ]

    author_candidates = []
    for name_query in name_queries:
        logging.info(f"[API] Querying SCOPUS: {name_query}")
        start = 0
        while True:
            params = {'query': name_query, 'start': start, 'count': 25}
            resp = requests.get(AUTHOR_SEARCH_URL, headers=headers, params=params)
            api_calls['author_search'] += 1
            if resp.status_code != 200:
                logging.error(f"[API] Author search failed: {resp.status_code}")
                break
            data = resp.json()
            entries = data.get('search-results', {}).get('entry', [])
            if not entries:
                break
            author_candidates.extend(entries)
            if len(author_candidates) >= max_candidates:
                break
            total = int(data['search-results']['opensearch:totalResults'])
            start += 25
            if start >= total:
                break
            time.sleep(1)

    print(f"\n[Internal] Found {len(author_candidates)} SCOPUS candidates.")
    for author in author_candidates:
        author_id = author.get('dc:identifier', '').split(':')[-1]
        full_name = f"{author.get('preferred-name', {}).get('given-name', '')} {author.get('preferred-name', {}).get('surname', '')}".strip()
        print(f"  - {full_name} (ID: {author_id})")

    best_score = 0
    matched_author = None
    candidate_scores = []

    for author in author_candidates:
        author_id = author.get('dc:identifier', '').split(':')[-1]
        full_name = f"{author.get('preferred-name', {}).get('given-name', '')} {author.get('preferred-name', {}).get('surname', '')}".strip()

        passed_name_check = name_similarity(first, last, full_name)
        if not passed_name_check:
            logging.info(f"[Internal] Skipping name mismatch: Input='{first} {last}' vs SCOPUS='{full_name}'")
            candidate_scores.append((author_id, full_name, 0, 'Name mismatch'))
            continue

        logging.info(f"[API] Checking author: {full_name} (ID: {author_id})")
        url = f"https://api.elsevier.com/content/author/author_id/{author_id}?view=ENHANCED"
        resp = requests.get(url, headers=headers)
        api_calls['author_retrieval'] += 1
        if resp.status_code != 200:
            logging.warning(f"[API] Failed to retrieve author {author_id}: {resp.status_code}")
            candidate_scores.append((author_id, full_name, 0, f"Failed to retrieve ({resp.status_code})"))
            continue

        try:
            aff_history = resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-history']['affiliation']
        except Exception as e:
            logging.warning(f"[Internal] No affiliation history for author {author_id}")
            candidate_scores.append((author_id, full_name, 0, "No affiliation history"))
            continue

        if isinstance(aff_history, dict):
            aff_history = [aff_history]

        score = 0
        matched_affils = set()
        for known_name, known_year in affil_year_pairs:
            for aff in aff_history:
                aff_name = aff.get('affil-name', '').lower()
                aff_year = aff.get('start-date')
                try:
                    aff_year = int(aff_year) if aff_year else None
                except:
                    aff_year = None
                if fuzzy_match(known_name.lower(), aff_name):
                    if aff_year is None or abs(aff_year - known_year) <= 6:
                        if known_name not in matched_affils:
                            logging.info(f"[Internal] Matched '{known_name}' ~ '{aff_name}' (aff year: {aff_year})")
                            score += 1
                            matched_affils.add(known_name)
                            break

        candidate_scores.append((author_id, full_name, score, "Matched" if score > 0 else "No matched affiliations"))

        if score > best_score:
            best_score = score
            matched_author = (author_id, full_name)

    print("\n=== CANDIDATE SCORES ===")
    for scopus_id, name, score, note in candidate_scores:
        print(f"{name} (ID: {scopus_id}) → Score: {score} [{note}]")

    print("\n=== SCOPUS API CALL STATS ===")
    print(f"Author search queries: {api_calls['author_search']}")
    print(f"Author retrieval calls: {api_calls['author_retrieval']}")

    if matched_author:
        print("\n=== BEST MATCH ===")
        print(f"Author: {matched_author[1]}")
        print(f"SCOPUS ID: {matched_author[0]}")
        print(f"Score: {best_score}")
    else:
        print("\n[Internal] No matching author found.")

# === TEST CALL ===
run_test_case(
    first="FIRSTNAMEHERE",
    last="LASTNAMEHERE",
    affil_year_pairs=[
        ("U1", YYYY),
        ("U2", YYYY)
    ]
)


# === Cell 6b: Main loop using Author Retrieval API (ENHANCED view, with name matching, API tracking, and result summary) ===
primary_output = []
secondary_output = []
max_candidates = 50  # throttle per row

results = []  # to hold all final matched authors and their publications
summary_log = []  # collect summary info per person

def name_similarity(input_first, input_last, candidate_fullname):
    parts = candidate_fullname.lower().split()
    if len(parts) < 2:
        return False
    candidate_first = parts[0]
    candidate_last = parts[-1]
    return (
        candidate_last == input_last.lower() and
        levenshtein_ratio(input_first.lower(), candidate_first) > 0.8
    )

# === Track API call counts ===
api_calls = {
    'author_search': 0,
    'author_retrieval': 0
}

for idx, row in df.iterrows():
    first = str(row.get('first_name', '')).strip()
    middle = str(row.get('middle_name', '')).strip()
    last = str(row.get('last_name', '')).strip()
    if not first or not last:
        continue

    excel_name = f"{first} {middle} {last}".strip()
    name_queries = [
        f"AUTHLASTNAME({last}) AND AUTHFIRST({first} {middle})" if middle else f"AUTHLASTNAME({last}) AND AUTHFIRST({first})",
        f"AUTHLASTNAME({last}) AND AUTHFIRST({first[0]})" if first else ""
    ]

    author_candidates = []
    for name_query in name_queries:
        if not name_query:
            continue
        logging.info(f"[API] Querying SCOPUS: {name_query}")
        start = 0
        while True:
            params = {'query': name_query, 'start': start, 'count': 25}
            resp = requests.get(AUTHOR_SEARCH_URL, headers=headers, params=params)
            api_calls['author_search'] += 1
            if resp.status_code != 200:
                logging.error(f"[API] Author search failed: {resp.status_code}")
                break
            data = resp.json()
            entries = data.get('search-results', {}).get('entry', [])
            if not entries:
                break
            author_candidates.extend(entries)
            if len(author_candidates) >= max_candidates:
                break
            total = int(data['search-results']['opensearch:totalResults'])
            start += 25
            if start >= total:
                break
            time.sleep(1)

    logging.info(f"[Internal] Found {len(author_candidates)} author candidates.")

    known_affils = []
    for i in range(1, 5):
        aff = str(row.get(f'affiliation_{i}', '')).strip()
        year = row.get(f'affiliation_{i}_year')
        if aff and pd.notna(year):
            known_affils.append((aff.lower(), int(year)))

    best_score = 0
    matched_author = None
    matched_pubs = []

    for author in author_candidates:
        author_id = author.get('dc:identifier', '').split(':')[-1]
        full_name = f"{author.get('preferred-name', {}).get('given-name', '')} {author.get('preferred-name', {}).get('surname', '')}".strip()

        if not name_similarity(first, last, full_name):
            logging.info(f"[Internal] Skipping name mismatch: Excel='{first} {last}' vs SCOPUS='{full_name}'")
            continue

        logging.info(f"[API] Checking author: {full_name} (ID: {author_id})")
        url = f"https://api.elsevier.com/content/author/author_id/{author_id}?view=ENHANCED"
        resp = requests.get(url, headers=headers)
        api_calls['author_retrieval'] += 1
        if resp.status_code != 200:
            logging.warning(f"[API] Failed to retrieve author {author_id}: {resp.status_code}")
            continue

        try:
            aff_history = resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-history']['affiliation']
        except Exception as e:
            logging.warning(f"[Internal] No affiliation history for author {author_id}")
            continue

        if isinstance(aff_history, dict):
            aff_history = [aff_history]

        score = 0
        matched_affils = set()
        for known_name, known_year in known_affils:
            for aff in aff_history:
                aff_name = aff.get('affil-name', '').lower()
                aff_year = aff.get('start-date')
                try:
                    aff_year = int(aff_year) if aff_year else None
                except:
                    aff_year = None
                if fuzzy_match(known_name, aff_name):
                    if aff_year is None or abs(aff_year - known_year) <= 6:
                        if known_name not in matched_affils:
                            logging.info(f"[Internal] Matched '{known_name}' ~ '{aff_name}' (aff year: {aff_year})")
                            score += 1
                            matched_affils.add(known_name)
                            break

        logging.info(f"[Internal] Score for {full_name} (ID {author_id}): {score}")

        if score > best_score:
            best_score = score
            matched_author = (author_id, full_name)
            matched_pubs = []  # optional: include this if needed later

    if matched_author:
        logging.info(f"[Internal] Selected author: {matched_author[1]} (ID: {matched_author[0]})")
        summary_log.append({
            'input_name': excel_name,
            'candidate_count': len(author_candidates),
            'selected_author': matched_author[1],
            'scopus_id': matched_author[0]
        })
        results.append({
            'author_id': matched_author[0],
            'author_name': matched_author[1],
            'publications': matched_pubs
        })
    else:
        summary_log.append({
            'input_name': excel_name,
            'candidate_count': len(author_candidates),
            'selected_author': None,
            'scopus_id': None
        })

# === Summary output ===
print("\n=== SCOPUS API CALL STATS ===")
print(f"Author search queries: {api_calls['author_search']}")
print(f"Author retrieval calls: {api_calls['author_retrieval']}")

print("\n=== PER-INPUT AUTHOR SUMMARY ===")
for entry in summary_log:
    print(f"Input: {entry['input_name']}")
    print(f"  Candidates Found: {entry['candidate_count']}")
    print(f"  Selected Author: {entry['selected_author'] or 'None'}")
    print(f"  SCOPUS ID: {entry['scopus_id'] or 'None'}")
    print("---")


# === Cell 7a: Process Primary Author Output ===
    for pub in matched_pubs:
        title = pub.get('dc:title', 'Untitled')
        year = pub.get('prism:coverDate', '')[:4]
        affil_str = "Affiliation Unknown"
        for auth in pub.get('author', []):
            if auth.get('authid') == matched_author[0]:
                affils = auth.get('affiliation', [])
                if isinstance(affils, dict): affils = [affils]
                affil_parts = []
                for aff in affils:
                    parts = [aff.get('affilname'), aff.get('affiliation-city'), aff.get('affiliation-country')]
                    affil_parts.append(", ".join([p for p in parts if p]))
                affil_str = " / ".join(affil_parts)
                break
        primary_output.append([matched_author[1], title, affil_str])

    # === Cell 7b: Process Co-authors ===
    for pub in matched_pubs:
        title = pub.get('dc:title', 'Untitled')
        for auth in pub.get('author', []):
            if auth.get('authid') == matched_author[0]:
                continue
            name = auth.get('authname', 'Name Unknown')
            affils = auth.get('affiliation', [])
            if isinstance(affils, dict): affils = [affils]
            affil_parts = []
            for aff in affils:
                parts = [aff.get('affilname'), aff.get('affiliation-city'), aff.get('affiliation-country')]
                affil_parts.append(", ".join([p for p in parts if p]))
            affil_str = " / ".join(affil_parts) if affil_parts else "Affiliation Unknown"
            secondary_output.append([name, matched_author[1], title, affil_str])

# === Cell 8: Save Output Files ===
output_dir = 'D:/aa030/output/'
pd.DataFrame(primary_output, columns=["Primary Author", "Paper Title", "Affiliation"]).to_csv(output_dir + 'primary_output.csv', index=False)
pd.DataFrame(secondary_output, columns=["Coauthor", "Primary Author", "Paper Title", "Affiliation"]).to_csv(output_dir + 'secondary_output.csv', index=False)

print("Files saved.")
