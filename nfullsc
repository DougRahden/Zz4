# === Cell 1: Install necessary packages ===
!pip install pandas openpyxl requests python-Levenshtein

# === Cell 2: Imports and logging ===
import pandas as pd
import requests
import time
import logging
from difflib import SequenceMatcher
from Levenshtein import ratio as levenshtein_ratio

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# === Cell 3: Configure API access ===
API_KEY = 'your-api-key-here'
INSTITUTION_TOKEN = 'your-institutional-token-here'

headers = {
    'X-ELS-APIKey': API_KEY,
    'X-ELS-Insttoken': INSTITUTION_TOKEN,
    'Accept': 'application/json'
}

AUTHOR_SEARCH_URL = "https://api.elsevier.com/content/search/author"
SCOPUS_SEARCH_URL = "https://api.elsevier.com/content/search/scopus"

# === Cell 4: Test SCOPUS API Key and Token ===
test_params = {
    'query': 'AUTHLASTNAME(Einstein) AND AUTHFIRST(Albert)',
    'count': 1
}

test_resp = requests.get(AUTHOR_SEARCH_URL, headers=headers, params=test_params)
print("Test Status Code:", test_resp.status_code)

# Show a short snippet of the response content (optional)
try:
    print("Test Response Snippet:", test_resp.json())
except Exception as e:
    print("Could not parse JSON. Raw text:", test_resp.text[:300])

# === Cell 5: Load Excel File ===
input_path = 'D:/aa030/input/aa-counterintel-input.xlsx'
df = pd.read_excel(input_path, engine='openpyxl')
print(f"Loaded {len(df)} authors from input file.")

# === Cell 6a: Define helper for fuzzy affiliation match ===
def fuzzy_match(a, b):
    a, b = a.lower(), b.lower()
    return levenshtein_ratio(a, b) > 0.80 or a in b or b in a

# === Cell 6bx-TEST: Debug test for a single author match ===

max_candidates = 50
api_calls = {'author_search': 0, 'author_retrieval': 0}

def name_similarity(input_first, input_last, candidate_fullname):
    parts = candidate_fullname.lower().split()
    if len(parts) < 2:
        return False
    candidate_first = parts[0]
    candidate_last = parts[-1]
    return (
        candidate_last == input_last.lower() and
        levenshtein_ratio(input_first.lower(), candidate_first) > 0.8
    )

def fuzzy_match(a, b):
    a, b = a.lower(), b.lower()
    return levenshtein_ratio(a, b) > 0.80 or a in b or b in a

def run_test_case(first, last, affil_year_pairs):
    name_queries = [
        f"AUTHLASTNAME({last}) AND AUTHFIRST({first})",
        f"AUTHLASTNAME({last}) AND AUTHFIRST({first[0]})"
    ]

    author_candidates = []
    for name_query in name_queries:
        logging.info(f"[API] Querying SCOPUS: {name_query}")
        start = 0
        while True:
            params = {'query': name_query, 'start': start, 'count': 25}
            resp = requests.get(AUTHOR_SEARCH_URL, headers=headers, params=params)
            api_calls['author_search'] += 1
            if resp.status_code != 200:
                logging.error(f"[API] Author search failed: {resp.status_code}")
                break
            data = resp.json()
            entries = data.get('search-results', {}).get('entry', [])
            if not entries:
                break
            author_candidates.extend(entries)
            if len(author_candidates) >= max_candidates:
                break
            total = int(data['search-results']['opensearch:totalResults'])
            start += 25
            if start >= total:
                break
            time.sleep(1)

    print(f"\n[Internal] Found {len(author_candidates)} SCOPUS candidates.")

    best_score = 0
    matched_author = None
    candidate_scores = []

    for author in author_candidates:
        author_id = author.get('dc:identifier', '').split(':')[-1]
        full_name = f"{author.get('preferred-name', {}).get('given-name', '')} {author.get('preferred-name', {}).get('surname', '')}".strip()

        if not name_similarity(first, last, full_name):
            logging.info(f"[Internal] Skipping name mismatch: Input='{first} {last}' vs SCOPUS='{full_name}'")
            continue

        logging.info(f"[API] Checking author: {full_name} (ID: {author_id})")
        url = f"https://api.elsevier.com/content/author/author_id/{author_id}?view=ENHANCED"
        resp = requests.get(url, headers=headers)
        api_calls['author_retrieval'] += 1
        if resp.status_code != 200:
            logging.warning(f"[API] Failed to retrieve author {author_id}: {resp.status_code}")
            continue

        try:
            aff_history = resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-history']['affiliation']
        except Exception as e:
            logging.warning(f"[Internal] No affiliation history for author {author_id}")
            continue

        if isinstance(aff_history, dict):
            aff_history = [aff_history]

        score = 0
        matched_affils = set()
        for known_name, known_year in affil_year_pairs:
            for aff in aff_history:
                aff_name = aff.get('affil-name', '').lower()
                aff_year = aff.get('start-date')
                try:
                    aff_year = int(aff_year) if aff_year else None
                except:
                    aff_year = None
                if fuzzy_match(known_name.lower(), aff_name):
                    if aff_year is None or abs(aff_year - known_year) <= 6:
                        if known_name not in matched_affils:
                            logging.info(f"[Internal] Matched '{known_name}' ~ '{aff_name}' (aff year: {aff_year})")
                            score += 1
                            matched_affils.add(known_name)
                            break

        candidate_scores.append((author_id, full_name, score))

        if score > best_score:
            best_score = score
            matched_author = (author_id, full_name)

    print("\n=== CANDIDATE SCORES ===")
    for scopus_id, name, score in candidate_scores:
        print(f"{name} (ID: {scopus_id}) â†’ Score: {score}")

    print("\n=== SCOPUS API CALL STATS ===")
    print(f"Author search queries: {api_calls['author_search']}")
    print(f"Author retrieval calls: {api_calls['author_retrieval']}")

    if matched_author:
        print("\n=== BEST MATCH ===")
        print(f"Author: {matched_author[1]}")
        print(f"SCOPUS ID: {matched_author[0]}")
        print(f"Score: {best_score}")
    else:
        print("\n[Internal] No matching author found.")

# === TEST CALL ===
run_test_case(
    first="FIRSTNAMEHERE",
    last="LASTNAMEHERE",
    affil_year_pairs=[
        ("U1", YYYY),
        ("U2", YYYY)
    ]
)


# === Cell 6b: Main loop using Author Retrieval API (ENHANCED view, with name matching, API tracking, and result summary) ===
primary_output = []
secondary_output = []
max_candidates = 50  # throttle per row

results = []  # to hold all final matched authors and their publications
summary_log = []  # collect summary info per person

def name_similarity(input_first, input_last, candidate_fullname):
    parts = candidate_fullname.lower().split()
    if len(parts) < 2:
        return False
    candidate_first = parts[0]
    candidate_last = parts[-1]
    return (
        candidate_last == input_last.lower() and
        levenshtein_ratio(input_first.lower(), candidate_first) > 0.8
    )

# === Track API call counts ===
api_calls = {
    'author_search': 0,
    'author_retrieval': 0
}

for idx, row in df.iterrows():
    first = str(row.get('first_name', '')).strip()
    middle = str(row.get('middle_name', '')).strip()
    last = str(row.get('last_name', '')).strip()
    if not first or not last:
        continue

    excel_name = f"{first} {middle} {last}".strip()
    name_queries = [
        f"AUTHLASTNAME({last}) AND AUTHFIRST({first} {middle})" if middle else f"AUTHLASTNAME({last}) AND AUTHFIRST({first})",
        f"AUTHLASTNAME({last}) AND AUTHFIRST({first[0]})" if first else ""
    ]

    author_candidates = []
    for name_query in name_queries:
        if not name_query:
            continue
        logging.info(f"[API] Querying SCOPUS: {name_query}")
        start = 0
        while True:
            params = {'query': name_query, 'start': start, 'count': 25}
            resp = requests.get(AUTHOR_SEARCH_URL, headers=headers, params=params)
            api_calls['author_search'] += 1
            if resp.status_code != 200:
                logging.error(f"[API] Author search failed: {resp.status_code}")
                break
            data = resp.json()
            entries = data.get('search-results', {}).get('entry', [])
            if not entries:
                break
            author_candidates.extend(entries)
            if len(author_candidates) >= max_candidates:
                break
            total = int(data['search-results']['opensearch:totalResults'])
            start += 25
            if start >= total:
                break
            time.sleep(1)

    logging.info(f"[Internal] Found {len(author_candidates)} author candidates.")

    known_affils = []
    for i in range(1, 5):
        aff = str(row.get(f'affiliation_{i}', '')).strip()
        year = row.get(f'affiliation_{i}_year')
        if aff and pd.notna(year):
            known_affils.append((aff.lower(), int(year)))

    best_score = 0
    matched_author = None
    matched_pubs = []

    for author in author_candidates:
        author_id = author.get('dc:identifier', '').split(':')[-1]
        full_name = f"{author.get('preferred-name', {}).get('given-name', '')} {author.get('preferred-name', {}).get('surname', '')}".strip()

        if not name_similarity(first, last, full_name):
            logging.info(f"[Internal] Skipping name mismatch: Excel='{first} {last}' vs SCOPUS='{full_name}'")
            continue

        logging.info(f"[API] Checking author: {full_name} (ID: {author_id})")
        url = f"https://api.elsevier.com/content/author/author_id/{author_id}?view=ENHANCED"
        resp = requests.get(url, headers=headers)
        api_calls['author_retrieval'] += 1
        if resp.status_code != 200:
            logging.warning(f"[API] Failed to retrieve author {author_id}: {resp.status_code}")
            continue

        try:
            aff_history = resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-history']['affiliation']
        except Exception as e:
            logging.warning(f"[Internal] No affiliation history for author {author_id}")
            continue

        if isinstance(aff_history, dict):
            aff_history = [aff_history]

        score = 0
        matched_affils = set()
        for known_name, known_year in known_affils:
            for aff in aff_history:
                aff_name = aff.get('affil-name', '').lower()
                aff_year = aff.get('start-date')
                try:
                    aff_year = int(aff_year) if aff_year else None
                except:
                    aff_year = None
                if fuzzy_match(known_name, aff_name):
                    if aff_year is None or abs(aff_year - known_year) <= 6:
                        if known_name not in matched_affils:
                            logging.info(f"[Internal] Matched '{known_name}' ~ '{aff_name}' (aff year: {aff_year})")
                            score += 1
                            matched_affils.add(known_name)
                            break

        logging.info(f"[Internal] Score for {full_name} (ID {author_id}): {score}")

        if score > best_score:
            best_score = score
            matched_author = (author_id, full_name)
            matched_pubs = []  # optional: include this if needed later

    if matched_author:
        logging.info(f"[Internal] Selected author: {matched_author[1]} (ID: {matched_author[0]})")
        summary_log.append({
            'input_name': excel_name,
            'candidate_count': len(author_candidates),
            'selected_author': matched_author[1],
            'scopus_id': matched_author[0]
        })
        results.append({
            'author_id': matched_author[0],
            'author_name': matched_author[1],
            'publications': matched_pubs
        })
    else:
        summary_log.append({
            'input_name': excel_name,
            'candidate_count': len(author_candidates),
            'selected_author': None,
            'scopus_id': None
        })

# === Summary output ===
print("\n=== SCOPUS API CALL STATS ===")
print(f"Author search queries: {api_calls['author_search']}")
print(f"Author retrieval calls: {api_calls['author_retrieval']}")

print("\n=== PER-INPUT AUTHOR SUMMARY ===")
for entry in summary_log:
    print(f"Input: {entry['input_name']}")
    print(f"  Candidates Found: {entry['candidate_count']}")
    print(f"  Selected Author: {entry['selected_author'] or 'None'}")
    print(f"  SCOPUS ID: {entry['scopus_id'] or 'None'}")
    print("---")


# === Cell 7a: Process Primary Author Output ===
    for pub in matched_pubs:
        title = pub.get('dc:title', 'Untitled')
        year = pub.get('prism:coverDate', '')[:4]
        affil_str = "Affiliation Unknown"
        for auth in pub.get('author', []):
            if auth.get('authid') == matched_author[0]:
                affils = auth.get('affiliation', [])
                if isinstance(affils, dict): affils = [affils]
                affil_parts = []
                for aff in affils:
                    parts = [aff.get('affilname'), aff.get('affiliation-city'), aff.get('affiliation-country')]
                    affil_parts.append(", ".join([p for p in parts if p]))
                affil_str = " / ".join(affil_parts)
                break
        primary_output.append([matched_author[1], title, affil_str])

    # === Cell 7b: Process Co-authors ===
    for pub in matched_pubs:
        title = pub.get('dc:title', 'Untitled')
        for auth in pub.get('author', []):
            if auth.get('authid') == matched_author[0]:
                continue
            name = auth.get('authname', 'Name Unknown')
            affils = auth.get('affiliation', [])
            if isinstance(affils, dict): affils = [affils]
            affil_parts = []
            for aff in affils:
                parts = [aff.get('affilname'), aff.get('affiliation-city'), aff.get('affiliation-country')]
                affil_parts.append(", ".join([p for p in parts if p]))
            affil_str = " / ".join(affil_parts) if affil_parts else "Affiliation Unknown"
            secondary_output.append([name, matched_author[1], title, affil_str])

# === Cell 8: Save Output Files ===
output_dir = 'D:/aa030/output/'
pd.DataFrame(primary_output, columns=["Primary Author", "Paper Title", "Affiliation"]).to_csv(output_dir + 'primary_output.csv', index=False)
pd.DataFrame(secondary_output, columns=["Coauthor", "Primary Author", "Paper Title", "Affiliation"]).to_csv(output_dir + 'secondary_output.csv', index=False)

print("Files saved.")
