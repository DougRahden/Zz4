# === Cell 6b: Full entity resolution logic with safe affiliation-current handling ===

from collections import defaultdict
import math

entity_resolution_output = []
summary_log = []
api_calls = {'author_search': 0, 'doc_search': 0}

max_docs_per_author = 100
fuzzy_affil_threshold = 0.9
fuzzy_city_threshold = 0.9
ignore_tokens = ["university", "college", "institute", "laboratory", "school", "of", "the", "and", "&", "center"]

def clean_for_matching(text):
    words = [w for w in text.lower().split() if w not in ignore_tokens]
    return " ".join(words)

def fuzzy_match_cleaned(a, b):
    a_clean = clean_for_matching(a)
    b_clean = clean_for_matching(b)
    return levenshtein_ratio(a_clean, b_clean) >= fuzzy_affil_threshold or a_clean in b_clean or b_clean in a_clean

def city_match(a, b):
    a, b = a.strip().lower(), b.strip().lower()
    return levenshtein_ratio(a, b) >= fuzzy_city_threshold or a in b or b in a

def search_scopus_authors(first, last):
    query = f"AUTHLASTNAME({last}) AND AUTHFIRST({first})"
    url = "https://api.elsevier.com/content/search/author"
    params = {'query': query, 'count': 25, 'start': 0}
    authors = []
    print(f"[API] Searching authors for: {first} {last}")
    while True:
        print(f"  → Page start={params['start']}")
        resp = requests.get(url, headers=headers, params=params)
        api_calls['author_search'] += 1
        if resp.status_code != 200:
            print(f"  [ERROR] Status {resp.status_code}")
            break
        entries = resp.json().get('search-results', {}).get('entry', [])
        for entry in entries:
            scopus_id = entry.get('dc:identifier', '').split(':')[-1]
            name_data = entry.get('preferred-name', {})
            full_name = f"{name_data.get('given-name', '')} {name_data.get('surname', '')}".strip()
            raw_affil = entry.get('affiliation-current')
            if isinstance(raw_affil, dict):
                current_affil = raw_affil.get('affiliation-name', '').strip()
                current_city = raw_affil.get('affiliation-city', '').strip().lower()
                current_country = raw_affil.get('affiliation-country', '').strip()
            else:
                current_affil = 'N/A'
                current_city = ''
                current_country = ''
            authors.append((scopus_id, full_name, current_affil, current_city, current_country))
        if len(entries) < 25:
            break
        params['start'] += 25
        time.sleep(1)
    return authors

def pull_documents_by_auid(scopus_id):
    url = "https://api.elsevier.com/content/search/scopus"
    docs = []
    params = {
        'query': f"AU-ID({scopus_id})",
        'count': 25,
        'start': 0,
        'view': 'COMPLETE',
        'sort': 'coverDate:desc'
    }
    while len(docs) < max_docs_per_author:
        print(f"[API] Pulling docs for SCOPUS ID {scopus_id}, start={params['start']}")
        resp = requests.get(url, headers=headers, params=params)
        api_calls['doc_search'] += 1
        if resp.status_code != 200:
            print(f"  [ERROR] Status {resp.status_code}")
            break
        entries = resp.json().get('search-results', {}).get('entry', [])
        print(f"  → Retrieved {len(entries)} docs this page")
        if not entries:
            break
        for doc in entries:
            if not doc.get('eid') or not doc.get('dc:title'):
                print(f"  [SKIP] Missing eid or title, skipping doc")
                continue
            docs.append(doc)
        params['start'] += 25
        if len(entries) < 25:
            print(f"  → Page returned less than 25 entries. Stopping pagination.")
            break
        time.sleep(1)
    print(f"  → Total documents collected: {len(docs)}")
    return docs

for idx, row in df.iterrows():
    first = str(row.get('first_name', '')).strip()
    middle = str(row.get('middle_name', '')).strip()
    middle = '' if middle == 'nan' or pd.isna(middle) else middle
    last = str(row.get('last_name', '')).strip()
    if not first or not last:
        continue
    input_name = " ".join([first, middle, last]).strip()
    print(f"\n[START] Processing {input_name}")

    known_affils = []
    for i in range(1, 5):
        aff = str(row.get(f'affiliation_{i}', '')).strip()
        raw_city = row.get(f'affiliation_{i}_city', '')
        city = str(raw_city).strip().lower() if pd.notna(raw_city) else ''
        year = row.get(f'affiliation_{i}_year')
        if aff and pd.notna(year):
            known_affils.append({
                'affil': aff.lower(),
                'city': city,
                'year': int(year),
                'priority': i
            })

    candidates = search_scopus_authors(first, last)
    best_match = None
    best_priority = float('inf')
    for scopus_id, full_name, current_affil, current_city, current_country in candidates:
        print(f"  → Candidate: {full_name} (ID: {scopus_id}) | Affil: {current_affil} | City: {current_city}")
        for ref in known_affils:
            city_match_ok = city_match(current_city, ref['city']) if current_city and ref['city'] else False
            affil_match_ok = fuzzy_match_cleaned(current_affil, ref['affil']) if current_affil != 'N/A' else False
            if city_match_ok or affil_match_ok:
                if ref['priority'] < best_priority:
                    best_match = (scopus_id, full_name, current_affil, current_city, current_country)
                    best_priority = ref['priority']
                    if affil_match_ok:
                        print(f"    [FUZZY MATCH] Affiliation matched '{ref['affil']}' (priority {ref['priority']})")
                    elif city_match_ok:
                        print(f"    [CITY MATCH] City matched '{ref['city']}' (priority {ref['priority']})")
                break

    if not best_match:
        summary_log.append({'input': input_name, 'scopus_id': None, 'matched_affil': None, 'docs': 0})
        print(f"  [MISS] No SCOPUS ID match for {input_name}")
        entity_resolution_output.append({
            'input_name': input_name,
            'matched_name': '',
            'scopus_id': '',
            'eid': '',
            'paper_title': '',
            'affiliation': '',
            'affiliation_city': '',
            'affiliation_country': '',
            'publication_date': ''
        })
        continue

    scopus_id, matched_name, matched_affil, matched_city, matched_country = best_match
    print(f"  [SELECTED] {matched_name} | SCOPUS ID: {scopus_id} | Affil: {matched_affil or 'N/A'}")

    docs = pull_documents_by_auid(scopus_id)
    summary_log.append({'input': input_name, 'scopus_id': scopus_id, 'matched_affil': matched_affil, 'docs': len(docs)})

    for doc in docs:
        authors = doc.get('author', [])
        eid = doc.get('eid')
        title = doc.get('dc:title', 'Untitled')
        pub_date = doc.get('prism:coverDate', 'Unknown')

        affil_str = ''
        affil_city = ''
        affil_country = ''
        for a in authors:
            if a.get('authid') == scopus_id:
                affils = a.get('affiliation', [])
                if isinstance(affils, dict):
                    affils = [affils]
                affil_parts = []
                for aff in affils:
                    aff_name = aff.get('affilname', '')
                    affil_city = aff.get('affiliation-city', '')
                    affil_country = aff.get('affiliation-country', '')
                    parts = [aff_name, affil_city, affil_country]
                    affil_parts.append(", ".join([p for p in parts if p]))
                affil_str = " / ".join(affil_parts)
                break

        entity_resolution_output.append({
            'input_name': input_name,
            'matched_name': matched_name,
            'scopus_id': scopus_id,
            'eid': eid,
            'paper_title': title,
            'affiliation': affil_str,
            'affiliation_city': affil_city,
            'affiliation_country': affil_country,
            'publication_date': pub_date
        })

# === Summary ===
print("\n=== API CALL STATS ===")
for k, v in api_calls.items():
    print(f"{k}: {v}")

print("\n=== ENTITY RESOLUTION SUMMARY ===")
for entry in summary_log:
    print(f"Input: {entry['input']} | SCOPUS ID: {entry['scopus_id'] or 'None'} | Affil: {entry['matched_affil'] or 'N/A'} | Docs: {entry['docs']}")
