# === Cell 6b: Entity Resolution with guaranteed author-paper affiliation mapping ===

from collections import defaultdict

entity_resolution_output = []
summary_log = []
api_calls = {'author_search': 0, 'doc_search': 0}

max_docs_per_author = 100
fuzzy_affil_threshold = 0.9
ignore_tokens = ["university", "college", "institute", "laboratory", "school", "of", "the", "and", "&", "center"]

def clean_for_matching(text):
    words = [w for w in text.lower().split() if w not in ignore_tokens]
    return " ".join(words)

def fuzzy_match_cleaned(a, b):
    a_clean = clean_for_matching(a)
    b_clean = clean_for_matching(b)
    return levenshtein_ratio(a_clean, b_clean) >= fuzzy_affil_threshold or a_clean in b_clean or b_clean in a_clean

def search_scopus_authors(first, last):
    query = f"AUTHLASTNAME({last}) AND AUTHFIRST({first})"
    url = "https://api.elsevier.com/content/search/author"
    params = {'query': query, 'count': 25, 'start': 0}
    authors = []
    print(f"[API] Searching authors for: {first} {last}")
    while True:
        print(f"  → Page start={params['start']}")
        resp = requests.get(url, headers=headers, params=params)
        api_calls['author_search'] += 1
        if resp.status_code != 200:
            print(f"  [ERROR] Status {resp.status_code}")
            break
        entries = resp.json().get('search-results', {}).get('entry', [])
        for entry in entries:
            scopus_id = entry.get('dc:identifier', '').split(':')[-1]
            name_data = entry.get('preferred-name', {})
            full_name = f"{name_data.get('given-name', '')} {name_data.get('surname', '')}".strip()
            raw_affil = entry.get('affiliation-current', {}).get('affiliation-name', '')
            current_affil = raw_affil.strip() if raw_affil else 'N/A'
            authors.append((scopus_id, full_name, current_affil))
        if len(entries) < 25:
            break
        params['start'] += 25
        time.sleep(1)
    return authors

def pull_documents_by_auid(scopus_id):
    url = "https://api.elsevier.com/content/search/scopus"
    docs = []
    params = {
        'query': f"AU-ID({scopus_id})",
        'count': 25,
        'start': 0,
        'view': 'COMPLETE',
        'sort': 'coverDate:desc'
    }
    while len(docs) < max_docs_per_author:
        print(f"[API] Pulling docs for SCOPUS ID {scopus_id}, start={params['start']}")
        resp = requests.get(url, headers=headers, params=params)
        api_calls['doc_search'] += 1
        if resp.status_code != 200:
            print(f"  [ERROR] Status {resp.status_code}")
            break
        entries = resp.json().get('search-results', {}).get('entry', [])
        print(f"  → Retrieved {len(entries)} docs this page")
        if not entries:
            break
        for doc in entries:
            if not doc.get('eid') or not doc.get('dc:title'):
                print(f"  [SKIP] Missing eid or title, skipping doc")
                continue
            docs.append(doc)
        params['start'] += 25
        if len(entries) < 25:
            print(f"  → Page returned less than 25 entries. Stopping pagination.")
            break
        time.sleep(1)
    print(f"  → Total documents collected: {len(docs)}")
    return docs

for idx, row in df.iterrows():
    first = str(row.get('first_name', '')).strip()
    middle = str(row.get('middle_name', '')).strip()
    last = str(row.get('last_name', '')).strip()
    if not first or not last:
        continue
    input_name = " ".join([first, middle, last]).strip()
    print(f"\n[START] Processing {input_name}")

    known_affils = []
    for i in range(1, 5):
        aff = str(row.get(f'affiliation_{i}', '')).strip()
        if aff:
            known_affils.append((aff.lower(), i))

    candidates = search_scopus_authors(first, last)
    best_match = None
    best_priority = float('inf')
    for scopus_id, full_name, current_affil in candidates:
        print(f"  → Candidate: {full_name} (ID: {scopus_id}) | Affil: {current_affil}")
        for affil, priority in known_affils:
            if current_affil != 'N/A' and current_affil.lower() == affil:
                best_match = (scopus_id, full_name, current_affil)
                best_priority = -1
                print(f"    [EXACT MATCH] '{current_affil}' == '{affil}'")
                break
            elif current_affil != 'N/A' and fuzzy_match_cleaned(current_affil, affil):
                if best_priority > priority:
                    best_match = (scopus_id, full_name, current_affil)
                    best_priority = priority
                    print(f"    [FUZZY MATCH] Fuzzy match to '{affil}' (priority {priority})")
                break

    if not best_match:
        summary_log.append({'input': input_name, 'scopus_id': None, 'matched_affil': None, 'docs': 0})
        print(f"  [MISS] No SCOPUS ID match for {input_name}")
        entity_resolution_output.append({
            'input_name': input_name,
            'matched_name': '',
            'scopus_id': '',
            'paper_title': '',
            'affiliation': '',
            'publication_date': ''
        })
        continue

    scopus_id, matched_name, matched_affil = best_match
    print(f"  [SELECTED] {matched_name} | SCOPUS ID: {scopus_id} | Affil: {matched_affil or 'N/A'}")

    docs = pull_documents_by_auid(scopus_id)
    summary_log.append({'input': input_name, 'scopus_id': scopus_id, 'matched_affil': matched_affil, 'docs': len(docs)})

    for doc in docs:
        authors = doc.get('author', [])
        doc_affils = doc.get('affiliation', [])
        if isinstance(doc_affils, dict):
            doc_affils = [doc_affils]
        affil_lookup = {a.get('@id'): a for a in doc_affils if '@id' in a}

        eid = doc.get('eid')
        title = doc.get('dc:title', 'Untitled')
        year = doc.get('prism:coverDate', 'Unknown')
        affil_str = ''

        for a in authors:
            if a.get('authid') == scopus_id:
                aff_data = a.get('affiliation', {})
                aff_id = aff_data.get('@id') if isinstance(aff_data, dict) else None
                aff_record = affil_lookup.get(aff_id, {})
                parts = [
                    aff_record.get('affilname'),
                    aff_record.get('affiliation-city'),
                    aff_record.get('affiliation-country')
                ]
                affil_str = ", ".join([p for p in parts if p])
                break

        entity_resolution_output.append({
            'input_name': input_name,
            'matched_name': matched_name,
            'scopus_id': scopus_id,
            'paper_title': title,
            'affiliation': affil_str,
            'publication_date': year
        })

# === Summary ===
print("\n=== API CALL STATS ===")
for k, v in api_calls.items():
    print(f"{k}: {v}")

print("\n=== ENTITY RESOLUTION SUMMARY ===")
for entry in summary_log:
    print(f"Input: {entry['input']} | SCOPUS ID: {entry['scopus_id'] or 'None'} | Affil: {entry['matched_affil'] or 'N/A'} | Docs: {entry['docs']}")
